{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core\n",
    "# TODO: Change 'core' to your target module name (e.g., utils, base, models, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Module\n",
    "\n",
    "> Foundation classes and functions for {PROJECT_NAME}\n",
    "\n",
    "This notebook demonstrates the core functionality of the library. It serves as both:\n",
    "- **Documentation**: Explains what the code does and why\n",
    "- **Implementation**: Contains the actual exported Python code\n",
    "- **Tests**: Validates behavior with executable examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import dependencies needed for both the library and notebook execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Core library imports - these will be exported to the Python module\n",
    "from typing import Optional, List, Dict, Any, Union\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Notebook-only imports - use tag-core test utilities instead of fastcore.test directly\n",
    "from tag.core.utils.my_test import *\n",
    "from fastcore.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Configure logging for the module\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# Notebook-only setup\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Data Structures\n",
    "\n",
    "Define the fundamental data structures used throughout the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class DataModel:\n",
    "    \"\"\"\n",
    "    Core data model representing {DESCRIPTION}.\n",
    "    \n",
    "    This class demonstrates:\n",
    "    - Using dataclasses for clean data modeling\n",
    "    - Type hints for clarity\n",
    "    - Docstrings following Google/NumPy style\n",
    "    \n",
    "    Args:\n",
    "        name: Human-readable identifier\n",
    "        value: Numeric value associated with this item\n",
    "        metadata: Optional dictionary for additional data\n",
    "    \n",
    "    Example:\n",
    "        ```python\n",
    "        item = DataModel(name=\"example\", value=42)\n",
    "        print(item.name)  # \"example\"\n",
    "        ```\n",
    "    \"\"\"\n",
    "    name: str\n",
    "    value: float\n",
    "    metadata: Optional[Dict[str, Any]] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate data after initialization.\"\"\"\n",
    "        if not self.name:\n",
    "            raise ValueError(\"name cannot be empty\")\n",
    "        if self.metadata is None:\n",
    "            self.metadata = {}\n",
    "    \n",
    "    def is_positive(self) -> bool:\n",
    "        \"\"\"Check if value is positive.\"\"\"\n",
    "        return self.value > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing DataModel\n",
    "\n",
    "Demonstrate usage and validate behavior with tests using tag-core test utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance\n",
    "item = DataModel(name=\"test\", value=42.0)\n",
    "print(f\"Created: {item}\")\n",
    "\n",
    "# Test basic functionality using tag.core.utils.my_test\n",
    "test_eq(item.name, \"test\")\n",
    "test_eq(item.value, 42.0)\n",
    "test_eq(item.is_positive(), True)\n",
    "test_eq(item.metadata, {})\n",
    "\n",
    "# Test with metadata\n",
    "item2 = DataModel(name=\"example\", value=-10.0, metadata={\"tag\": \"negative\"})\n",
    "test_eq(item2.is_positive(), False)\n",
    "test_eq(item2.metadata[\"tag\"], \"negative\")\n",
    "\n",
    "# Test validation\n",
    "test_fail(lambda: DataModel(name=\"\", value=0), contains=\"cannot be empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Processing Functions\n",
    "\n",
    "Implement the main processing logic for the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_data(\n",
    "    items: List[DataModel],\n",
    "    threshold: float = 0.0,\n",
    "    reverse: bool = False\n",
    ") -> List[DataModel]:\n",
    "    \"\"\"\n",
    "    Process a collection of data items with filtering and sorting.\n",
    "    \n",
    "    This function demonstrates:\n",
    "    - Working with collections of custom objects\n",
    "    - Configurable behavior via parameters\n",
    "    - Clear documentation of processing logic\n",
    "    \n",
    "    Args:\n",
    "        items: Collection of DataModel instances to process\n",
    "        threshold: Minimum value to include (default: 0.0)\n",
    "        reverse: Sort in descending order if True (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        Filtered and sorted list of DataModel instances\n",
    "    \n",
    "    Example:\n",
    "        ```python\n",
    "        items = [\n",
    "            DataModel(\"a\", 10.0),\n",
    "            DataModel(\"b\", -5.0),\n",
    "            DataModel(\"c\", 20.0)\n",
    "        ]\n",
    "        result = process_data(items, threshold=0.0)\n",
    "        # Returns [DataModel(\"a\", 10.0), DataModel(\"c\", 20.0)]\n",
    "        ```\n",
    "    \"\"\"\n",
    "    # Filter based on threshold\n",
    "    filtered = [item for item in items if item.value >= threshold]\n",
    "    \n",
    "    # Sort by value\n",
    "    sorted_items = sorted(filtered, key=lambda x: x.value, reverse=reverse)\n",
    "    \n",
    "    logger.debug(f\"Processed {len(items)} items -> {len(sorted_items)} results\")\n",
    "    \n",
    "    return sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing process_data\n",
    "\n",
    "Validate with various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data\n",
    "test_items = [\n",
    "    DataModel(\"first\", 10.0),\n",
    "    DataModel(\"second\", -5.0),\n",
    "    DataModel(\"third\", 20.0),\n",
    "    DataModel(\"fourth\", 0.0)\n",
    "]\n",
    "\n",
    "# Test basic filtering\n",
    "result = process_data(test_items, threshold=0.0)\n",
    "test_eq(len(result), 3)  # Excludes negative value\n",
    "test_eq([r.name for r in result], [\"fourth\", \"first\", \"third\"])\n",
    "\n",
    "# Test with higher threshold\n",
    "result = process_data(test_items, threshold=5.0)\n",
    "test_eq(len(result), 2)\n",
    "test_eq([r.name for r in result], [\"first\", \"third\"])\n",
    "\n",
    "# Test reverse sorting\n",
    "result = process_data(test_items, threshold=0.0, reverse=True)\n",
    "test_eq([r.name for r in result], [\"third\", \"first\", \"fourth\"])\n",
    "\n",
    "# Test empty list\n",
    "result = process_data([])\n",
    "test_eq(result, [])\n",
    "\n",
    "print(\"✓ All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Processor Class\n",
    "\n",
    "For more complex scenarios, use a class to maintain state and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    Stateful processor for DataModel collections.\n",
    "    \n",
    "    This class demonstrates:\n",
    "    - Object-oriented design patterns\n",
    "    - Configuration management\n",
    "    - State tracking\n",
    "    \n",
    "    Args:\n",
    "        threshold: Default threshold for filtering\n",
    "        auto_sort: Enable automatic sorting (default: True)\n",
    "    \n",
    "    Example:\n",
    "        ```python\n",
    "        processor = DataProcessor(threshold=5.0)\n",
    "        items = [DataModel(\"a\", 10), DataModel(\"b\", 3)]\n",
    "        result = processor.process(items)\n",
    "        print(processor.stats)  # {'processed': 2, 'filtered': 1}\n",
    "        ```\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold: float = 0.0, auto_sort: bool = True):\n",
    "        self.threshold = threshold\n",
    "        self.auto_sort = auto_sort\n",
    "        self.stats = {'processed': 0, 'filtered': 0}\n",
    "    \n",
    "    def process(\n",
    "        self, \n",
    "        items: List[DataModel], \n",
    "        threshold: Optional[float] = None\n",
    "    ) -> List[DataModel]:\n",
    "        \"\"\"\n",
    "        Process items using instance configuration.\n",
    "        \n",
    "        Args:\n",
    "            items: Items to process\n",
    "            threshold: Override instance threshold if provided\n",
    "        \n",
    "        Returns:\n",
    "            Processed items\n",
    "        \"\"\"\n",
    "        # Use instance threshold if not overridden\n",
    "        thresh = threshold if threshold is not None else self.threshold\n",
    "        \n",
    "        # Update statistics\n",
    "        self.stats['processed'] += len(items)\n",
    "        \n",
    "        # Filter\n",
    "        result = [item for item in items if item.value >= thresh]\n",
    "        self.stats['filtered'] += len(items) - len(result)\n",
    "        \n",
    "        # Sort if enabled\n",
    "        if self.auto_sort:\n",
    "            result = sorted(result, key=lambda x: x.value)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def reset_stats(self):\n",
    "        \"\"\"Reset processing statistics.\"\"\"\n",
    "        self.stats = {'processed': 0, 'filtered': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create processor with default threshold\n",
    "processor = DataProcessor(threshold=5.0)\n",
    "\n",
    "# Process test data\n",
    "items = [\n",
    "    DataModel(\"a\", 10.0),\n",
    "    DataModel(\"b\", 3.0),\n",
    "    DataModel(\"c\", 15.0)\n",
    "]\n",
    "\n",
    "result = processor.process(items)\n",
    "test_eq(len(result), 2)  # Only items >= 5.0\n",
    "test_eq([r.name for r in result], [\"a\", \"c\"])  # Auto-sorted\n",
    "\n",
    "# Check statistics\n",
    "test_eq(processor.stats['processed'], 3)\n",
    "test_eq(processor.stats['filtered'], 1)\n",
    "\n",
    "# Test threshold override\n",
    "result = processor.process(items, threshold=0.0)\n",
    "test_eq(len(result), 3)  # All items included\n",
    "\n",
    "# Test without auto-sort\n",
    "processor2 = DataProcessor(threshold=0.0, auto_sort=False)\n",
    "result = processor2.process(items)\n",
    "test_eq([r.name for r in result], [\"a\", \"b\", \"c\"])  # Original order\n",
    "\n",
    "# Test reset\n",
    "processor.reset_stats()\n",
    "test_eq(processor.stats, {'processed': 0, 'filtered': 0})\n",
    "\n",
    "print(\"✓ All processor tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Helper functions that support the core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def summarize_collection(items: List[DataModel]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate summary statistics for a collection.\n",
    "    \n",
    "    Args:\n",
    "        items: Collection to summarize\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with count, min, max, mean, and positive_count\n",
    "    \"\"\"\n",
    "    if not items:\n",
    "        return {\n",
    "            'count': 0,\n",
    "            'min': None,\n",
    "            'max': None,\n",
    "            'mean': None,\n",
    "            'positive_count': 0\n",
    "        }\n",
    "    \n",
    "    values = [item.value for item in items]\n",
    "    \n",
    "    return {\n",
    "        'count': len(items),\n",
    "        'min': min(values),\n",
    "        'max': max(values),\n",
    "        'mean': sum(values) / len(values),\n",
    "        'positive_count': sum(1 for item in items if item.is_positive())\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test summary function\n",
    "items = [\n",
    "    DataModel(\"a\", 10.0),\n",
    "    DataModel(\"b\", -5.0),\n",
    "    DataModel(\"c\", 20.0)\n",
    "]\n",
    "\n",
    "summary = summarize_collection(items)\n",
    "test_eq(summary['count'], 3)\n",
    "test_eq(summary['min'], -5.0)\n",
    "test_eq(summary['max'], 20.0)\n",
    "test_close(summary['mean'], 8.33, eps=0.01)  # Using test_close for floating point\n",
    "test_eq(summary['positive_count'], 2)\n",
    "\n",
    "# Test empty collection\n",
    "empty_summary = summarize_collection([])\n",
    "test_eq(empty_summary['count'], 0)\n",
    "test_eq(empty_summary['min'], None)\n",
    "\n",
    "print(\"✓ Summary tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Example\n",
    "\n",
    "Putting it all together in a realistic workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic dataset\n",
    "dataset = [\n",
    "    DataModel(\"item_1\", 15.5, {\"category\": \"A\"}),\n",
    "    DataModel(\"item_2\", -3.2, {\"category\": \"B\"}),\n",
    "    DataModel(\"item_3\", 42.0, {\"category\": \"A\"}),\n",
    "    DataModel(\"item_4\", 8.7, {\"category\": \"C\"}),\n",
    "    DataModel(\"item_5\", -1.0, {\"category\": \"B\"}),\n",
    "    DataModel(\"item_6\", 23.4, {\"category\": \"A\"}),\n",
    "]\n",
    "\n",
    "print(\"Original dataset:\")\n",
    "print(summarize_collection(dataset))\n",
    "print()\n",
    "\n",
    "# Process with function\n",
    "print(\"Using process_data function:\")\n",
    "result = process_data(dataset, threshold=10.0)\n",
    "print(f\"Filtered to {len(result)} items: {[r.name for r in result]}\")\n",
    "print()\n",
    "\n",
    "# Process with class\n",
    "print(\"Using DataProcessor class:\")\n",
    "processor = DataProcessor(threshold=0.0, auto_sort=True)\n",
    "result = processor.process(dataset)\n",
    "print(f\"Processed {len(result)} items\")\n",
    "print(f\"Statistics: {processor.stats}\")\n",
    "print(f\"Summary: {summarize_collection(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices Demonstrated\n",
    "\n",
    "This notebook illustrates several nbdev and Python best practices:\n",
    "\n",
    "1. **Clear Structure**: Logical progression from imports → data structures → functions → classes → utilities\n",
    "2. **Documentation**: Every exported item has detailed docstrings\n",
    "3. **Type Hints**: All functions and methods specify parameter and return types\n",
    "4. **Testing**: Tests accompany every code section using `tag.core.utils.my_test`\n",
    "5. **Examples**: Concrete usage examples in docstrings and test cells\n",
    "6. **Separation**: `#|export` clearly marks library code vs. notebook-only code\n",
    "7. **Incremental**: Building from simple to complex (dataclass → function → class)\n",
    "8. **Custom Test Utils**: Uses project-specific test utilities (`tag.core.utils.my_test`) that extend fastcore\n",
    "\n",
    "## Customization Guide\n",
    "\n",
    "To adapt this template for your project:\n",
    "\n",
    "1. **Update `#|default_exp`**: Change `core` to your module name\n",
    "2. **Replace placeholders**: Search for `{PROJECT_NAME}`, `{DESCRIPTION}`, etc.\n",
    "3. **Modify DataModel**: Replace with your actual data structures\n",
    "4. **Update functions**: Replace `process_data` with your core logic\n",
    "5. **Adapt processor**: Modify `DataProcessor` for your use case\n",
    "6. **Add imports**: Include your specific dependencies\n",
    "7. **Update tests**: Create tests specific to your functionality\n",
    "8. **Test imports**: Ensure `tag.core.utils.my_test` is available (install tag-core as dependency)\n",
    "9. **Expand sections**: Add new sections as needed (e.g., I/O, configuration, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "This cell exports the notebook to a Python module. Run `nbdev_export` in the terminal or let git hooks handle it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
